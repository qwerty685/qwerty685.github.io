---
sort: 4
---



# 基于GAN网络的方法

## 大纲

+ 生成对抗神经网络介绍和PassGAN介绍
+ 使用生成对抗神经网络的优点
+ PassGAN介绍
+ PassGAN实践结果



## 内容

​		生成对抗神经网络（Generative Adversarial Network，简称GAN）通过让两个神经网络互相博弈的方法进行学习，目的是估计高维空间的密度。生成对抗神经网络由一个生成网络和一个判别网络构成。生成网络负责控制模型生成模仿真实数据集的输出，判别网络从真实数据或者生成网络产生的数据中分辨出真实数据。口令猜测的过程也是从真实数据中训练模型，最终生成尽可能与真实数据集相近的数据集的过程。因此，Hitaj等人[1]提出PassGAN方法，将生成对抗神经网络用于密码猜测。

​		在基于规则的密码猜测方法中，规则由相关的专业研究者分析密码数据得出。这些规则覆盖大部分密码数据，但是如果需要进一步覆盖更多的数据，需要进一步研究需要分析更多的密码规律，这些分析都需要专业的人手动完成。因此穷尽所有的规则非常困难。现有的研究表明神经网络有足够的学习能力和表达能力捕捉密码中的规律。使用GAN神经网络进行密码猜测的方法的好处在于密码生成的规则不需要手动创建，而是根据生成网络和判别网络的对抗自动优化密码生成模型。

​		Improved training of Wasserstein GANs（简称IWGAN）是用于文本生成的GAN网络中较稳定的实现方法，因此PassGAN的实现基于IWGAN。构建IWGAN和PassGAN最重要的组成部分是残差网络块（Residual Blocks）。在训练深度神经网络时，初始训练误差随着层数的增加而减小。但是在达到一定的层数后，训练错误又开始增加。残差网络的提出就是为了解决这类问题。与其他深度神经网络相比，在单纯的向前传播的基础上，残差网络块增加了跃层链接（Shortcut Connection）。相关研究表明，残差网络能够减少梯度消失的情况出现，减少训练错误。PassGAN使用的残差网络块由两个一维卷积层组成，通过ReLU激活函数相互连接。

​		PassGAN的由生成网络和判别网络组成。判别网络处理来自训练数据的密码以及生成器生成的密码样本。根据判别网络的反馈，生成网络对模型参数进行微调，生成与训练集样本分布相似的密码集。在PassGAN中，判别网络由一层卷积层、5个残差网络块和线性层组成。生成网络由线性层、5个残差网络块、卷积层以及softmax层组成。使用残差网络块连接能够减少梯度消失的情况，增加PassGAN对密码文本的学习能力。

​		训练结束后，PassGAN中生成网络的输出将作为PassGAN训练结果。在实践中，PassGAN与常用的工具Hashcat Bese64、Hashcat gen2、JtR（John the Ripper）、Markov和PCFG进行比较。比较的方法为其他工具生成一定数量的密码，PassGAN尝试对相同的密码集生成相同猜测率的密码。换句话说，在密码猜测率相同的情况下，比较密码生成数量。实践的结果表明，尽管PassGAN没有关于密码结构的知识作为输入，PassGAN依然能够从密码序列中提取足够的信息，生成足够猜测率的密码。与依赖人工生成规则和马尔可夫式密码猜测方法不同，PassGAN需要更多的猜测数量。PassGAN需要的猜测数量比常用的工具相差一个数量级。

​		PassGAN在密码集交叉猜测方面也有贡献。在实验中，PassGAN在Rockyou的密码集上训练，将训练的模型用于LinkedIn密码集的猜测。尽管所有工具包括PassGAN的猜测命中率都有所下降，PassGAN能够在较少的猜测次数内匹配比Hashcat更多的密码。这说明PassGAN能够提取密码的公共特征进行跨密码集的口令猜测。

​		与深度神经网络的方法类似，PassGAN也能够匹配已有规则未覆盖的密码空间的一部分。在密码猜测过程中，使用多种猜测方法组合的方式能够帮助猜测更多的密码。组合的效率依赖各种方法产生的密码集之间的重叠率。如果两种方法产生的密码存在较大差异（较小的重叠），那么将两者组合后能够产生较高的组合效果。相反如果两种方法生成的密码集存在大量的相同密码，那么两者组合后将产生比较低的组合效果。评估PassGAN时，研究者删除了Hashcat best64匹配的所有密码，形成新的密码集。PassGAN在新的密码集中，Rockyou的猜测率能够达到51%，LinkedIn的猜测率能够达到73%。结果表明PassGAN学习了人工产生规则之外的密码组成特性，能够与已有工具达成比较好的组合效果。

​		基于PassGAN的密码猜测方法也存在不少不足。首先，对于同样的密码集生成相同的密码猜测率，PassGAN需要生成的密码数量与其他工具的密码数量相差一个数量级。尽管随着密码储存代价地降低，猜测密码规模的影响不是特别严重。但是更大的猜测数意味着更低的命中率，PassGAN相对其他工具的实际使用价值也相应降低。此外，由于GAN网络在训练时的不稳定性，PassGAN的训练结果可能不符合预期。PassGAN中生成网络更新的梯度来自判别网络的反馈，如果存在一种生成网络的输出，输出的结果并不接近真实数据，但是判别网络认可了输出，那么接下来生成网络继续生成类似的数据。如此反复，GAN输出的结果将与真实数据的特性偏离，导致最终结果的不理想。



## References

> + PassGAN：A Deep Learning Approach for Password Guessing